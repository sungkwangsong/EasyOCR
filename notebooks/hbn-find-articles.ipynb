{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPa5TADBtsNqbYOSo6kB6RT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sungkwangsong/EasyOCR/blob/master/notebooks/hbn-find-articles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_bqLTYnn7G6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "378a9e7b-f7e1-47a8-f731-175a8cbc199c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/Repositories/Hibrainnet"
      ],
      "metadata": {
        "id": "oppUboIqUi9d",
        "outputId": "75d560a8-ff7c-4547-fb46-923e39af7819",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Repositories/Hibrainnet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 필요한 라이브러리 설치\n",
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Mn2gtu32dFkb",
        "outputId": "e22635f5-4f35-4e0d-cafa-87f918a9b381",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.48.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.5.1+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.28.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2. 환경변수 추가\n",
        "HBN_DATA_DIR_PATH=\"/content/drive/MyDrive/Workspaces/Hibrainnet/hbn-scholar/data\"\n",
        "HBN_DATA_ARTICLES_DIR_PATH=f\"{HBN_DATA_DIR_PATH}/articles\""
      ],
      "metadata": {
        "id": "4ysvmUfMeGuL"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import numpy as np\n",
        "import json\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ],
      "metadata": {
        "id": "4oRRxVggiMKb"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_papers = [\n",
        "    {\n",
        "        \"title\": \"딥러닝 기반 한국어 자연어처리 기술 동향\",\n",
        "        \"authors\": [\"김철수\"],\n",
        "        \"co_authors\": [\"이영희\", \"박지민\", \"정동훈\"],\n",
        "        \"abstract\": \"최근 딥러닝 기술의 발전으로 자연어처리 분야에서 큰 성과가 있었다. 특히 한국어 처리에 있어 형태소 분석, 개체명 인식, 감정 분석 등 다양한 태스크에서 성능이 크게 향상되었다. 본 논문에서는 한국어 자연어처리 분야의 최신 딥러닝 기술 동향을 살펴보고, 향후 발전 방향을 제시한다.\",\n",
        "        \"journal\": \"한국정보과학회논문지\",\n",
        "        \"year\": 2022,\n",
        "        \"citations\": 125,\n",
        "        \"keywords\": [\"자연어처리\", \"딥러닝\", \"한국어\", \"인공지능\"]\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"미세먼지가 호흡기 질환에 미치는 영향 연구\",\n",
        "        \"authors\": [\"박성민\"],\n",
        "        \"co_authors\": [\"김태호\", \"이준영\"],\n",
        "        \"abstract\": \"대기오염물질 중 하나인 미세먼지(PM10)와 초미세먼지(PM2.5)가 인체의 호흡기 질환 발병률에 미치는 영향을 분석하였다. 서울시의 5년간의 대기질 측정 데이터와 호흡기 질환 진료 기록을 활용하여 상관관계를 도출하였으며, 특히 노약자층에서 유의미한 영향이 관찰되었다.\",\n",
        "        \"journal\": \"대한환경의학회지\",\n",
        "        \"year\": 2023,\n",
        "        \"citations\": 45,\n",
        "        \"keywords\": [\"미세먼지\", \"호흡기질환\", \"환경의학\", \"공중보건\"]\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"기계학습을 이용한 텍스트 마이닝 기반 감성분석\",\n",
        "        \"authors\": [\"정보람\"],\n",
        "        \"co_authors\": [\"송민준\", \"강현우\"],\n",
        "        \"abstract\": \"소셜미디어 데이터에서 감성을 추출하기 위해 기계학습 알고리즘을 활용한 텍스트 마이닝 방법론을 제안한다. SVM, Random Forest, LSTM 등 다양한 알고리즘을 비교 실험하였으며, 특히 한국어 텍스트의 특성을 고려한 전처리 방법을 적용하여 성능을 개선하였다.\",\n",
        "        \"journal\": \"한국빅데이터학회논문지\",\n",
        "        \"year\": 2023,\n",
        "        \"citations\": 32,\n",
        "        \"keywords\": [\"텍스트마이닝\", \"감성분석\", \"기계학습\", \"소셜미디어\"]\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"친환경 건축물의 에너지 효율성 분석\",\n",
        "        \"authors\": [\"이지원\"],\n",
        "        \"co_authors\": [\"한동석\", \"임수진\"],\n",
        "        \"abstract\": \"본 연구는 친환경 건축물의 에너지 효율성을 분석하고 개선 방안을 제시한다. 패시브 하우스 설계 요소가 건물의 에너지 소비량에 미치는 영향을 실증적으로 분석하였으며, 신재생 에너지 시스템의 통합 방안도 함께 검토하였다.\",\n",
        "        \"journal\": \"대한건축학회논문집\",\n",
        "        \"year\": 2022,\n",
        "        \"citations\": 67,\n",
        "        \"keywords\": [\"친환경건축\", \"에너지효율\", \"패시브하우스\", \"신재생에너지\"]\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"영유아의 스마트기기 사용이 언어발달에 미치는 영향\",\n",
        "        \"authors\": [\"최유진\"],\n",
        "        \"co_authors\": [\"박민서\", \"김도윤\"],\n",
        "        \"abstract\": \"만 2-5세 영유아의 스마트기기 사용 실태를 조사하고 언어발달과의 관계를 분석하였다. 과도한 스마트기기 노출이 언어발달 지연과 관련이 있음을 확인하였으며, 적절한 사용 가이드라인과 대안적 언어활동을 제시한다.\",\n",
        "        \"journal\": \"한국아동교육학회지\",\n",
        "        \"year\": 2023,\n",
        "        \"citations\": 28,\n",
        "        \"keywords\": [\"영유아교육\", \"언어발달\", \"스마트기기\", \"아동발달\"]\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"인공지능 기반 학습자 맞춤형 교육 시스템 개발\",\n",
        "        \"authors\": [\"장현수\"],\n",
        "        \"co_authors\": [\"김민지\", \"이성호\"],\n",
        "        \"abstract\": \"학습자의 성취도와 학습 패턴을 분석하여 개인화된 학습 콘텐츠를 제공하는 AI 기반 교육 시스템을 개발하였다. 머신러닝 알고리즘을 활용하여 학습자의 특성을 파악하고, 최적화된 학습 경로를 추천하는 방법을 제안한다.\",\n",
        "        \"journal\": \"한국교육공학회논문지\",\n",
        "        \"year\": 2023,\n",
        "        \"citations\": 52,\n",
        "        \"keywords\": [\"교육공학\", \"인공지능\", \"맞춤형교육\", \"이러닝\"]\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"한국 전통 발효식품의 항산화 활성 연구\",\n",
        "        \"authors\": [\"김지현\"],\n",
        "        \"co_authors\": [\"이상훈\", \"박소연\"],\n",
        "        \"abstract\": \"김치, 된장, 고추장 등 한국 전통 발효식품의 항산화 활성을 분석하였다. 발효 과정에서 생성되는 다양한 생리활성 물질을 확인하고, 이들의 항산화 메커니즘을 규명하였다. 특히 유산균 발효에 의한 항산화 활성 증가 현상에 주목하였다.\",\n",
        "        \"journal\": \"한국식품과학회지\",\n",
        "        \"year\": 2022,\n",
        "        \"citations\": 89,\n",
        "        \"keywords\": [\"발효식품\", \"항산화\", \"전통식품\", \"식품과학\"]\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "# # JSON 파일로 저장\n",
        "# with open(f'{HBN_DATA_PATH}/sample_papers.json', 'w', encoding='utf-8') as f:\n",
        "    # json.dump(sample_papers, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zey5cltsdyzw"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. BERT 모델 및 토크나이저 로드\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "e538Ibt9hRq6"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. 논문 검색을 위한 클래스 정의\n",
        "class PaperSearchEngine:\n",
        "    def __init__(self, papers):\n",
        "        self.papers = papers\n",
        "        self.model = model\n",
        "        self.paper_embeddings = None\n",
        "        self._create_embeddings()\n",
        "\n",
        "    def _create_embeddings(self):\n",
        "        # 논문 제목과 초록을 결합하여 임베딩 생성\n",
        "        texts = [f\"{paper['title']} {paper['abstract']}\" for paper in self.papers]\n",
        "        self.paper_embeddings = self.model.encode(texts)\n",
        "\n",
        "    def search(self, query, top_k=3):\n",
        "        # 쿼리 임베딩 생성\n",
        "        query_embedding = self.model.encode([query])\n",
        "\n",
        "        # 코사인 유사도 계산\n",
        "        similarities = cosine_similarity(query_embedding, self.paper_embeddings)[0]\n",
        "\n",
        "        # 상위 k개 논문 찾기\n",
        "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
        "\n",
        "        results = []\n",
        "        for idx in top_indices:\n",
        "            results.append({\n",
        "                'paper': self.papers[idx],\n",
        "                'similarity_score': similarities[idx]\n",
        "            })\n",
        "\n",
        "        return results"
      ],
      "metadata": {
        "id": "zA0WLS-rhyTf"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. 검색 엔진 초기화 및 테스트\n",
        "def test_search_engine():\n",
        "    # # JSON 파일 로드\n",
        "    # with open('sample_papers.json', 'r', encoding='utf-8') as f:\n",
        "        # papers = json.load(f)\n",
        "\n",
        "    # 검색 엔진 초기화\n",
        "    search_engine = PaperSearchEngine(sample_papers)\n",
        "\n",
        "    # 테스트 쿼리 실행\n",
        "    test_query=\"한국어 자연어처리 감성분석\"\n",
        "    results = search_engine.search(test_query)\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f\"Query: {test_query}\\n\")\n",
        "    for i, result in enumerate(results, 1):\n",
        "        paper = result['paper']\n",
        "        score = result['similarity_score']\n",
        "        print(f\"Result {i}:\")\n",
        "        print(f\"Title: {paper['title']}\")\n",
        "        print(f\"Authors: {', '.join(paper['authors'] + paper['co_authors'])}\")\n",
        "        print(f\"Year: {paper['year']}\")\n",
        "        print(f\"Similarity Score: {score:.4f}\")\n",
        "        print()\n"
      ],
      "metadata": {
        "id": "mkraui2RjrNi"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 실행\n",
        "test_search_engine()"
      ],
      "metadata": {
        "id": "jdGYwAwAj1t8",
        "outputId": "1425274d-89ab-40f9-8b73-5e1c5fd99015",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: 한국어 자연어처리 감성분석\n",
            "\n",
            "Result 1:\n",
            "Title: 영유아의 스마트기기 사용이 언어발달에 미치는 영향\n",
            "Authors: 최유진, 박민서, 김도윤\n",
            "Year: 2023\n",
            "Similarity Score: 0.5697\n",
            "\n",
            "Result 2:\n",
            "Title: 딥러닝 기반 한국어 자연어처리 기술 동향\n",
            "Authors: 김철수, 이영희, 박지민, 정동훈\n",
            "Year: 2022\n",
            "Similarity Score: 0.5334\n",
            "\n",
            "Result 3:\n",
            "Title: 친환경 건축물의 에너지 효율성 분석\n",
            "Authors: 이지원, 한동석, 임수진\n",
            "Year: 2022\n",
            "Similarity Score: 0.5293\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 7. 대화형 검색 인터페이스\n",
        "def interactive_search():\n",
        "    # # 검색 엔진 초기화\n",
        "    # with open('sample_papers.json', 'r', encoding='utf-8') as f:\n",
        "        # papers = json.load(f)\n",
        "    search_engine = PaperSearchEngine(sample_papers)\n",
        "\n",
        "    while True:\n",
        "        query = input(\"\\nEnter your search query (or 'quit' to exit): \")\n",
        "        if query.lower() == 'quit':\n",
        "            break\n",
        "\n",
        "        results = search_engine.search(query)\n",
        "\n",
        "        print(\"\\nSearch Results:\")\n",
        "        for i, result in enumerate(results, 1):\n",
        "            paper = result['paper']\n",
        "            score = result['similarity_score']\n",
        "            print(f\"\\nResult {i}:\")\n",
        "            print(f\"Title: {paper['title']}\")\n",
        "            print(f\"Authors: {', '.join(paper['authors'] + paper['co_authors'])}\")\n",
        "            print(f\"Journal: {paper['journal']}\")\n",
        "            print(f\"Year: {paper['year']}\")\n",
        "            print(f\"Citations: {paper['citations']}\")\n",
        "            print(f\"Similarity Score: {score:.4f}\")\n",
        "            print(f\"Abstract: {paper['abstract'][:200]}...\")\n",
        "\n",
        "# 메인 실행 코드\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Testing search engine with sample query...\")\n",
        "    test_search_engine()\n",
        "\n",
        "    print(\"\\nStarting interactive search...\")\n",
        "    interactive_search()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "SVYhcG5kbm6r",
        "outputId": "3f8769a2-cae5-4e1b-bfae-4eb39aa74c7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing search engine with sample query...\n",
            "Query: transformer architecture for natural language processing\n",
            "\n",
            "Result 1:\n",
            "Title: Attention Is All You Need\n",
            "Authors: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit\n",
            "Year: 2017\n",
            "Similarity Score: 0.4659\n",
            "\n",
            "Result 2:\n",
            "Title: BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\n",
            "Authors: Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova\n",
            "Year: 2019\n",
            "Similarity Score: 0.4295\n",
            "\n",
            "Result 3:\n",
            "Title: GPT-3: Language Models are Few-Shot Learners\n",
            "Authors: Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah\n",
            "Year: 2020\n",
            "Similarity Score: 0.2973\n",
            "\n",
            "\n",
            "Starting interactive search...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-792567ef323e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nStarting interactive search...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0minteractive_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-37-792567ef323e>\u001b[0m in \u001b[0;36minteractive_search\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nEnter your search query (or 'quit' to exit): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'quit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}